{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFM2gSTGObkb"
   },
   "outputs": [],
   "source": [
    "# convert HTML caracters to normal letters \n",
    "#  https://github.com/piegu/language-models/blob/master/lm3-portuguese-classifier-olist.ipynb \n",
    "from  cconverter import *  \n",
    "\n",
    "\n",
    "#df2[reviews] = df2[reviews].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "def removerAcentosECaracteresEspeciais(palavra):\n",
    "\n",
    "    # Unicode normalize transforma um caracter em seu equivalente em latin.\n",
    "    nfkd = unicodedata.normalize('NFKD', palavra)\n",
    "    palavraSemAcento = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
    "\n",
    "    # Usa expressão regular para retornar a palavra apenas com números, letras e espaço\n",
    "    return re.sub('[^a-zA-Z0-9 \\\\\\]', '', palavraSemAcento)\n",
    "@feliphebueno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the title name in the text field\n",
    "def split_title_from_text(text):\n",
    "    words = text.split(\"\\n\\n\")\n",
    "    if len(words) >= 2:\n",
    "        return ''.join(words[1:])\n",
    "    else:\n",
    "        return ''.join(words)\n",
    "    \n",
    "LANG_TEXT['text'] = LANG_TEXT['text'].apply(lambda x: split_title_from_text(x))\n",
    "\n",
    "#LANG_TEXT['text'].apply(lambda x: len(x.split(\" \"))).sum()    ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "texts = texts.apply(fixup).values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxWtVQacQTxC"
   },
   "outputs": [],
   "source": [
    "#PREENCHIMENTO DE NULOS / SINONIMOS / CR ,LF REMOVAL !!!!\n",
    "\n",
    "## PREENCHIMENTO DE NULOS !!!! NAO ESQUECER\n",
    "print(train[train['cli_desc'].isnull()])\n",
    "train['cli_desc'].fillna(\"$$$$$$\",inplace=True)\n",
    "train.fillna(\"$$$$$$\",inplace=True)\n",
    "\n",
    "#DELETE \\n \\r  = CR AND LF\n",
    "\n",
    "col = [ 'poy_desc',  'cli_desc'] \n",
    "\n",
    "for c in col:\n",
    "  train[c] = train[c].map(lambda  x: x.replace('\\n', '').replace('\\r', ''))\n",
    "\n",
    "###  TROCA DE SINONIMOS\n",
    "\n",
    "trocar\tpor\n",
    "0\ttermopar\ttermoresistencia\n",
    "1\tvalv\tvalvula\n",
    "2\tsup.\tsuporte\n",
    "\n",
    "\n",
    "def troca_string(x):\n",
    "  for match in range(len(sinonimo)):\n",
    "    p = re.compile(sinonimo['trocar'][match],re.IGNORECASE)\n",
    "    str = sinonimo['por'][match]\n",
    "    #print(match,p,str)\n",
    "    x = p.sub(str.__add__('     '),x,0)  \n",
    "  return x\n",
    "\n",
    "train['cli_desc'] = train['cli_desc'].map(troca_string)\n",
    "train['poy_desc'] = train['poy_desc'].map(troca_string)\n",
    "\n",
    "\n",
    "#remover duplicados\n",
    "train[train.duplicated(subset=['cli_cod'], keep='first')]\n",
    "train[train.duplicated(subset=None, keep='first')].count()\n",
    "train[train.duplicated(subset=None, keep='first')].index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  trocar ; ^ por espaço\n",
    "def format_inicial(train,coluna):\n",
    "  format_ini1 = lambda  x: re.sub(r'([;^])', r' ', x,0)        \n",
    "  \n",
    "  train[coluna] = train[coluna].map(format_ini1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remover acentos\n",
    "cols = train.select_dtypes(include=[np.object]).columns\n",
    "train[cols] = train[cols].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuation removal\n",
    "s = \"string. With. 2,3 3. 4, Punctuation?\"\n",
    "regex = r'(?<!\\d)[.,;:?!](?!\\d)'\n",
    "re.sub(regex, \"\", s, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  varias regex em poy2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IN EXCEL,SAVE AS CSV COMMA DELIMITED , e UTF-8  ( dentro dos Tools)\n",
    "#df=pd.read_csv('plan2.csv',sep=';',encoding='ISO-8859-1',lineterminator='\\n')\n",
    "#df=pd.read_csv('s1.csv',sep=';',encoding='ISO-8859-1',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP TIPS\n",
    "Latin-1  = iso-8859-1\n",
    "train = pd.read_excel(path/'poy1.xlsx')   #,encoding=\"latin-1\" ,,, opcional para ler arquivo em portugues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLIT BIG FILE IN SLICES OF 100K LINES, LAST FILES ARE EMPTY\n",
    "#split every 10 lines, -l=xxxx\n",
    "#split -d -a3 -l 10 --additional-suffix=.csv a11.csv mydata_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retira brancos ,, NAO PODE RETIRAR BRANCOS -- P.EX \"PAR \" correto e nao \"PAR\"\n",
    "#tipo1_ind =[x.rstrip() for x in tipo1_ind]\n",
    "\n",
    "# transform in lowercase\n",
    "#tipo1_ind =[x.lower() for x in tipo1_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TIPS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
